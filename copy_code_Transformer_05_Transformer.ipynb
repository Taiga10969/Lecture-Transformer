{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzhPSEA+x0Osy+YhpqYmiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taiga10969/Lecture-Transformer/blob/main/copy_code_Transformer_05_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 写経して理解するTransformer_05：Transformer\n",
        "\n",
        "01〜04で作成してきた各機構を用いてTransformerを構築していく．"
      ],
      "metadata": {
        "id": "Nvl91jgzqf7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要ライブラリのインポート"
      ],
      "metadata": {
        "id": "caTBFVoItExo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xCffw1dJoyiA"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各クラスの定義"
      ],
      "metadata": {
        "id": "-kduGxZ6tdei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model) # torch.nn の nn.Embedding を利用\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x：torch.Size([1, 7]) << [batch_size, src_len]\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded : torch.Size([1, 7, 128]) << [batch_size, src_len, d_model]\n",
        "        return embedded"
      ],
      "metadata": {
        "id": "1cvY5YehTFAr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2*i) / d_model)))\n",
        "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2*i) / d_model)))\n",
        "\n",
        "        self.pe = nn.Parameter(pe, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        ret = math.sqrt(self.d_model) * x + self.pe[:seq_len, :].unsqueeze(0)\n",
        "        return ret\n",
        "\n",
        "    def get_pe(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        return self.pe[:seq_len, :].unsqueeze(0)"
      ],
      "metadata": {
        "id": "AKvqQG7UTF4U"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        attention_score = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.depth, dtype=torch.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            attention_score += mask\n",
        "\n",
        "        attention_weights = F.softmax(attention_score, dim=-1)\n",
        "        attention = torch.matmul(attention_weights, value)\n",
        "        attention = attention.permute(0, 2, 1, 3).contiguous()\n",
        "        attention = attention.view(batch_size, -1, self.d_model)\n",
        "\n",
        "        return self.W_o(attention)"
      ],
      "metadata": {
        "id": "TgX6hh4iTMhV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, hidden_dim, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_1 = nn.Linear(dim, hidden_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(hidden_dim, dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear_2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gD3mXhzMo1hn"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder の構築\n",
        "Encoderブロックを複数積層してEncoderを構築するため，<br>\n",
        "EncoderBlockをクラスで定義し，そのクラスをインスタンスとして複数呼び出すEncoderクラスを作成する．"
      ],
      "metadata": {
        "id": "N3e7XbQMo3ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.MHA = MultiHeadAttention(d_model, num_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm2 = nn.LayerNorm([d_model])\n",
        "        self.FFN = FeedForwardNetwork(d_model, hidden_dim)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "      # self-Attention >> Q，K，Vに同じデータを流す\n",
        "      Q = K = V = _x = x\n",
        "\n",
        "      x = self.MHA(Q, K, V, mask)\n",
        "      x = self.dropout_1(x)\n",
        "      x = x + _x # Add\n",
        "      x = self.layer_norm1(x) # Norm\n",
        "\n",
        "      _x = x\n",
        "\n",
        "      x = self.FFN(x)\n",
        "      x = self.dropout_2(x)\n",
        "      x = x + _x #Add\n",
        "      x = self.layer_norm2(x) # Norm\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "LMguJwbtSpCp"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, max_seq_len, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.PE = PositionalEncoder(d_model, max_seq_len)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.EncoderBlocks = nn.ModuleList([EncoderBlock(d_model, num_heads, hidden_dim) for _ in range(6)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.embed(x)\n",
        "        x = x*(self.d_model**0.5)\n",
        "        x = self.PE(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = torch.where(mask == 1, torch.tensor(0), torch.tensor(float('-inf')))\n",
        "\n",
        "        for i in range(6):\n",
        "            x = self.EncoderBlocks[i](x, mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vnVW__fntOHZ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Decoder の構築\n",
        "Decoderブロックを複数積層してDecoderを構築するため，<br>\n",
        "DecoderBlockをクラスで定義し，そのクラスをインスタンスとして複数呼び出すDecoderクラスを作成する．"
      ],
      "metadata": {
        "id": "GhrX4Bvgx_17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.MHA_1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.MHA_2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.layer_norm_1 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm_2 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm_3 = nn.LayerNorm([d_model])\n",
        "\n",
        "        self.FFN = FeedForwardNetwork(d_model, hidden_dim)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, encoder_output, decoder_mask=None, encoder_mask=None):\n",
        "        # Decoder の一つ目のMHAは，self AttentionのMasked Multi-Head Attentionとなっており，入力QKVは，全て同じデータ\n",
        "        Q = K = V = _x = tgt\n",
        "\n",
        "        # 情報の先読みを防止するマスクの作成\n",
        "        seq_len = tgt.size(1)\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len) * -float('inf'), diagonal=1)\n",
        "        mask = mask.unsqueeze(0).unsqueeze(1) # バッチとヘッドの次元を追加\n",
        "\n",
        "        if decoder_mask is not None:\n",
        "            decoder_mask = torch.where(decoder_mask == 1, torch.tensor(0), torch.tensor(float('-inf')))\n",
        "            mask = mask + decoder_mask\n",
        "\n",
        "        x = self.MHA_1(Q, K, V, mask)\n",
        "        x = self.dropout_1(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_1(x)\n",
        "\n",
        "        # ここまでアーキテクチャ図のDecoderの下半分\n",
        "        # ここからアーキテクチャ図のDecoderの上半分\n",
        "\n",
        "        Q = x # queryには下半分からの出力を\n",
        "        _x = x\n",
        "        K = V = encoder_output # key,valueにはencoderからの出力を\n",
        "\n",
        "        x = self.MHA_2(Q, K, V, encoder_mask)\n",
        "        x = self.dropout_2(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_2(x)\n",
        "\n",
        "        _x = x\n",
        "\n",
        "        x = self.FFN(x)\n",
        "        x = self.dropout_3(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0Ghwh4uGx_Zi"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, max_seq_len, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "\n",
        "        self.PE = PositionalEncoder(d_model, max_seq_len)\n",
        "\n",
        "        self.DecoderBlocks = nn.ModuleList([DecoderBlock(d_model, num_heads, hidden_dim) for _ in range(6)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, tgt, encoder_output, mask=None, encoder_mask=None):\n",
        "        x = self.embed(tgt)\n",
        "        x = x*(self.d_model**0.5)\n",
        "        x = self.PE(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(6):\n",
        "            x = self.DecoderBlocks[i](x, encoder_output, mask, encoder_mask)\n",
        "\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jC2vxFvTstJb"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer実装"
      ],
      "metadata": {
        "id": "h17ROvarSMS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size_jp, vocab_size_en, d_model, num_heads, max_seq_len, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size_jp, d_model, num_heads, max_seq_len, hidden_dim)\n",
        "        self.decoder = Decoder(vocab_size_en, d_model, num_heads, max_seq_len, hidden_dim)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        encoder_output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, encoder_output, tgt_mask, src_mask)\n",
        "        return output"
      ],
      "metadata": {
        "id": "3tEuWtgWSMAS"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformerの動作確認"
      ],
      "metadata": {
        "id": "YJPhgwtJTnhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, AutoTokenizer\n",
        "# 文字列をトークンのID列に変換するトークナイザーはGPT-2のものを使用します\n",
        "# 日本語用と英語用でそれぞれ定義\n",
        "tokenizer_jp = AutoTokenizer.from_pretrained(\"colorfulscoop/gpt2-small-ja\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',\n",
        "                                          #add_bos_token = True\n",
        "                                          )\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# 入力するtextを定義\n",
        "text_jp = '人工知能 (AI) は、推論・判断などの知的な機能を備えたコンピュータ・システムのことです。'\n",
        "\n",
        "# 出力を期待するtext (翻訳結果) を定義\n",
        "text = \"Artificial intelligence (AI) is a computer system equipped with intelligent functions such as reasoning and judgment.\"\n",
        "\n",
        "# 入力するtextをトークナイザーを用いて数値(id)化する\n",
        "inputs_jp = tokenizer_jp(text_jp,\n",
        "                         padding=True,\n",
        "                         truncation=True,\n",
        "                         return_tensors='pt',)\n",
        "outputs_en = tokenizer(text,\n",
        "                       padding=True,\n",
        "                       truncation=True,\n",
        "                       return_tensors='pt',)\n",
        "\n",
        "# モデルに入力するID列を表示・形状を確認\n",
        "\n",
        "print(\"inputs_jp['input_ids']　: \", inputs_jp['input_ids'])\n",
        "print(\"inputs_jp['input_ids'].shape　: \", inputs_jp['input_ids'].shape)\n",
        "print(\"inputs_jp['input_ids'] token : \", tokenizer_jp.convert_ids_to_tokens(inputs_jp['input_ids'][0]))\n",
        "\n",
        "print(\"outputs_en['input_ids']　: \", outputs_en['input_ids'])\n",
        "print(\"outputs_en['input_ids'].shape　: \", outputs_en['input_ids'].shape)\n",
        "print(\"outputs_en['input_ids'] token : \", tokenizer.convert_ids_to_tokens(outputs_en['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vepwZISVuCqG",
        "outputId": "0c0097af-dc7c-4330-825b-9353130f2671"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs_jp['input_ids']　:  tensor([[27193,    71,  5257,    12,    19,     9,     6, 26805,    11,  3731,\n",
            "           134,   808,   141,   693,  8238,  2606,    11, 10149,   641,   318,\n",
            "             7]])\n",
            "inputs_jp['input_ids'].shape　:  torch.Size([1, 21])\n",
            "inputs_jp['input_ids'] token :  ['人工知能', '▁(', 'AI', ')', '▁', 'は', '、', '推論', '・', '判断', 'などの', '知', '的な', '機能', 'を備えた', 'コンピュータ', '・', 'システムの', 'ことで', 'す', '。']\n",
            "outputs_en['input_ids']　:  tensor([[ 8001,  9542,  4430,   357, 20185,     8,   318,   257,  3644,  1080,\n",
            "         10911,   351, 12661,  5499,   884,   355, 14607,   290,  8492,    13]])\n",
            "outputs_en['input_ids'].shape　:  torch.Size([1, 20])\n",
            "outputs_en['input_ids'] token :  ['Art', 'ificial', 'Ġintelligence', 'Ġ(', 'AI', ')', 'Ġis', 'Ġa', 'Ġcomputer', 'Ġsystem', 'Ġequipped', 'Ġwith', 'Ġintelligent', 'Ġfunctions', 'Ġsuch', 'Ġas', 'Ġreasoning', 'Ġand', 'Ġjudgment', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_jp = tokenizer_jp.vocab_size\n",
        "vocab_size_en = tokenizer_jp.vocab_size\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "max_seq_len = 256\n",
        "hidden_dim = 256\n",
        "\n",
        "model = Transformer(vocab_size_jp = vocab_size_jp,\n",
        "                    vocab_size_en = vocab_size_en,\n",
        "                    d_model = d_model,\n",
        "                    num_heads = num_heads,\n",
        "                    max_seq_len = max_seq_len,\n",
        "                    hidden_dim = hidden_dim)\n",
        "\n",
        "output = model(src = inputs_jp['input_ids'],\n",
        "               tgt = outputs_en['input_ids'],\n",
        "               src_mask = inputs_jp['attention_mask'],\n",
        "               tgt_mask = outputs_en['attention_mask'])\n",
        "\n",
        "print(\"output.shape : \", output.shape)\n",
        "\n",
        "outputs_IDs = torch.argmax(output, dim=-1)\n",
        "print(\"outputs_IDs : \", outputs_IDs)\n",
        "\n",
        "# モデルが出力した数値(id)を各単語に逆変換\n",
        "generated_text = tokenizer.decode(outputs_IDs[0])\n",
        "print(\"generated_text : \", generated_text)\n",
        "print(\"model_output token : \", tokenizer.convert_ids_to_tokens(outputs_IDs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDoH6L8ZsreK",
        "outputId": "acbc202a-52f0-46f4-d8d7-05ae0587e14a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output.shape :  torch.Size([1, 20, 32000])\n",
            "outputs_IDs :  tensor([[10013, 10388,    88, 15909, 30198, 28016, 24371, 11900,  8524, 31477,\n",
            "         10796, 22039,   303, 14237, 28863,  5878,  8341, 28826, 27332, 31768]])\n",
            "generated_text :   visiting contraryy adjacent Films Whereas Console /*then squads coins\"><ve summitornings 2001 listsseed �Init\n",
            "model_output token :  ['Ġvisiting', 'Ġcontrary', 'y', 'Ġadjacent', 'ĠFilms', 'ĠWhereas', 'ĠConsole', 'Ġ/*', 'then', 'Ġsquads', 'Ġcoins', '\"><', 've', 'Ġsummit', 'ornings', 'Ġ2001', 'Ġlists', 'seed', 'Ġï', 'Init']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "現状は何も学習していない乱数によるパラメータなので，期待している次単語予測による文章が生成できていないが，<br>\n",
        "Transformerの大まかなデータの流れはこのようになっている．<br>\n",
        "<br>\n",
        "このプログラムを参考に，色々データの中身や形状をPrint()して表示させてみて，理解につなげてみよう！<br>\n",
        "<br>\n",
        "以上<br>\n",
        "<br>\n",
        "中部大学 機械知覚&ロボティクスグループ（藤吉研究室）<br>\n",
        "増田 大河\n"
      ],
      "metadata": {
        "id": "u37SRcmNa4ZO"
      }
    }
  ]
}