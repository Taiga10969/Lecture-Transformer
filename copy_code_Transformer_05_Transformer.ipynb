{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOrtrxsVe0L6wZLcjl5jC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taiga10969/Lecture-Transformer/blob/main/copy_code_Transformer_05_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 写経して理解するTransformer_05：Transformer\n",
        "\n",
        "01〜04で作成してきた各機構を用いてTransformerを構築していく．"
      ],
      "metadata": {
        "id": "Nvl91jgzqf7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要ライブラリのインポート"
      ],
      "metadata": {
        "id": "caTBFVoItExo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xCffw1dJoyiA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各クラスの定義"
      ],
      "metadata": {
        "id": "-kduGxZ6tdei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model) # torch.nn の nn.Embedding を利用\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x：torch.Size([1, 7]) << [batch_size, src_len]\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded : torch.Size([1, 7, 128]) << [batch_size, src_len, d_model]\n",
        "        return embedded"
      ],
      "metadata": {
        "id": "1cvY5YehTFAr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2*i) / d_model)))\n",
        "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2*i) / d_model)))\n",
        "\n",
        "        self.pe = nn.Parameter(pe, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        ret = math.sqrt(self.d_model) * x + self.pe[:seq_len, :].unsqueeze(0)\n",
        "        return ret\n",
        "\n",
        "    def get_pe(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        return self.pe[:seq_len, :].unsqueeze(0)"
      ],
      "metadata": {
        "id": "AKvqQG7UTF4U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        attention_score = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.depth, dtype=torch.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            attention_score += mask\n",
        "\n",
        "        attention_weights = F.softmax(attention_score, dim=-1)\n",
        "        attention = torch.matmul(attention_weights, value)\n",
        "        attention = attention.permute(0, 2, 1, 3).contiguous()\n",
        "        attention = attention.view(batch_size, -1, self.d_model)\n",
        "\n",
        "        return self.W_o(attention)"
      ],
      "metadata": {
        "id": "TgX6hh4iTMhV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self, dim, hidden_dim, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_1 = nn.Linear(dim, hidden_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear_2 = nn.Linear(hidden_dim, dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear_2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gD3mXhzMo1hn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder の構築\n",
        "Encoderブロックを複数積層してEncoderを構築するため，<br>\n",
        "EncoderBlockをクラスで定義し，そのクラスをインスタンスとして複数呼び出すEncoderクラスを作成する．"
      ],
      "metadata": {
        "id": "N3e7XbQMo3ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.MHA = MultiHeadAttention(d_model, num_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm2 = nn.LayerNorm([d_model])\n",
        "        self.FFN = FeedForwardNetwork(d_model, hidden_dim)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "      # self-Attention >> Q，K，Vに同じデータを流す\n",
        "      Q = K = V = _x = x\n",
        "\n",
        "      x = self.MHA(Q, K, V, mask)\n",
        "      x = self.dropout_1(x)\n",
        "      x = x + _x # Add\n",
        "      x = self.layer_norm1(x) # Norm\n",
        "\n",
        "      _x = x\n",
        "\n",
        "      x = self.FFN(x)\n",
        "      x = self.dropout_2(x)\n",
        "      x = x + _x #Add\n",
        "      x = self.layer_norm2(x) # Norm\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "LMguJwbtSpCp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, max_seq_len, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.PE = PositionalEncoder(d_model, max_seq_len)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.EncoderBlocks = nn.ModuleList([EncoderBlock(d_model, num_heads, hidden_dim) for _ in range(6)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.embed(x)\n",
        "        x = x*(self.d_model**0.5)\n",
        "        x = self.PE(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = torch.where(mask == 1, torch.tensor(0), torch.tensor(float('-inf')))\n",
        "\n",
        "        for i in range(6):\n",
        "            x = self.EncoderBlocks[i](x, mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vnVW__fntOHZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Decoder の構築\n",
        "Decoderブロックを複数積層してDecoderを構築するため，<br>\n",
        "DecoderBlockをクラスで定義し，そのクラスをインスタンスとして複数呼び出すDecoderクラスを作成する．"
      ],
      "metadata": {
        "id": "GhrX4Bvgx_17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.MHA_1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.MHA_2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.layer_norm_1 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm_2 = nn.LayerNorm([d_model])\n",
        "        self.layer_norm_3 = nn.LayerNorm([d_model])\n",
        "\n",
        "        self.FFN = FeedForwardNetwork(d_model, hidden_dim)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, encoder_output, decoder_mask=None, encoder_mask=None):\n",
        "        # Decoder の一つ目のMHAは，self AttentionのMasked Multi-Head Attentionとなっており，入力QKVは，全て同じデータ\n",
        "        Q = K = V = _x = tgt\n",
        "\n",
        "        # 情報の先読みを防止するマスクの作成\n",
        "        seq_len = tgt.size(1)\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len) * -float('inf'), diagonal=1)\n",
        "        mask = mask.unsqueeze(0).unsqueeze(1) # バッチとヘッドの次元を追加\n",
        "\n",
        "        if decoder_mask is not None:\n",
        "            decoder_mask = torch.where(decoder_mask == 1, torch.tensor(0), torch.tensor(float('-inf')))\n",
        "            mask = mask + decoder_mask\n",
        "\n",
        "        x = self.MHA_1(Q, K, V, mask)\n",
        "        x = self.dropout_1(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_1(x)\n",
        "\n",
        "        # ここまでアーキテクチャ図のDecoderの下半分\n",
        "        # ここからアーキテクチャ図のDecoderの上半分\n",
        "\n",
        "        Q = x # queryには下半分からの出力を\n",
        "        _x = x\n",
        "        K = V = encoder_output # key,valueにはencoderからの出力を\n",
        "\n",
        "        x = self.MHA_2(Q, K, V, encoder_mask)\n",
        "        x = self.dropout_2(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_2(x)\n",
        "\n",
        "        _x = x\n",
        "\n",
        "        x = self.FFN(x)\n",
        "        x = self.dropout_3(x)\n",
        "        x = x + _x\n",
        "        x = self.layer_norm_3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0Ghwh4uGx_Zi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, max_seq_len, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "\n",
        "        self.PE = PositionalEncoder(d_model, max_seq_len)\n",
        "\n",
        "        self.DecoderBlocks = nn.ModuleList([DecoderBlock(d_model, num_heads, hidden_dim) for _ in range(6)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, tgt, encoder_output, mask=None, encoder_mask=None):\n",
        "        x = self.embed(tgt)\n",
        "        x = x*(self.d_model**0.5)\n",
        "        x = self.PE(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(6):\n",
        "            x = self.DecoderBlocks[i](x, encoder_output, mask, encoder_mask)\n",
        "\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jC2vxFvTstJb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer実装"
      ],
      "metadata": {
        "id": "h17ROvarSMS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size_en, vocab_size_jp, d_model, num_heads, max_seq_len, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size_en, d_model, num_heads, max_seq_len, hidden_dim)\n",
        "        self.decoder = Decoder(vocab_size_jp, d_model, num_heads, max_seq_len, hidden_dim)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        encoder_output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, encoder_output, tgt_mask, src_mask)\n",
        "        return output"
      ],
      "metadata": {
        "id": "3tEuWtgWSMAS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformerの動作確認"
      ],
      "metadata": {
        "id": "YJPhgwtJTnhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, AutoTokenizer\n",
        "# 文字列をトークンのID列に変換するトークナイザーはGPT-2のものを使用します\n",
        "# 日本語用と英語用でそれぞれ定義\n",
        "tokenizer_jp = AutoTokenizer.from_pretrained(\"colorfulscoop/gpt2-small-ja\",\n",
        "                                               add_bos_token = True\n",
        "                                               )\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',\n",
        "                                            add_bos_token = True\n",
        "                                            )\n",
        "\n",
        "tokenizer_jp.add_special_tokens({'bos_token': '<sos>'})\n",
        "tokenizer_jp.add_special_tokens({'pad_token': '<pad>'})\n",
        "tokenizer_jp.add_special_tokens({'eos_token': '<eos>'})\n",
        "tokenizer.add_special_tokens({'bos_token': '<sos>'})\n",
        "tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
        "tokenizer.add_special_tokens({'eos_token': '<eos>'})\n",
        "\n",
        "# 入力するtextを定義\n",
        "text_en = 'That is a great idea.'\n",
        "\n",
        "# 出力を期待するtext (翻訳結果) を定義\n",
        "text_jp = \"それは素晴らしいアイデアだ。\"\n",
        "\n",
        "# 入力するtextをトークナイザーを用いて数値(id)化する\n",
        "inputs = tokenizer(text_en,\n",
        "                   padding=True,\n",
        "                   truncation=True,\n",
        "                   max_length=64,\n",
        "                   return_tensors='pt',)\n",
        "\n",
        "outputs = tokenizer_jp(text_jp,\n",
        "                        padding=True,\n",
        "                        truncation=True,\n",
        "                        max_length=64,\n",
        "                        return_tensors='pt',)\n",
        "\n",
        "# モデルに入力するID列を表示・形状を確認\n",
        "\n",
        "print(\"inputs['input_ids']　: \", inputs['input_ids'])\n",
        "print(\"inputs['input_ids'].shape　: \", inputs['input_ids'].shape)\n",
        "print(\"inputs['input_ids'] token : \", tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
        "\n",
        "print(\"outputs['input_ids']　: \", outputs['input_ids'])\n",
        "print(\"outputs['input_ids'].shape　: \", outputs['input_ids'].shape)\n",
        "print(\"outputs['input_ids'] token : \", tokenizer_jp.convert_ids_to_tokens(outputs['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vepwZISVuCqG",
        "outputId": "5109f4e9-66e2-4dcf-bbb5-1fe7c4399e3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['input_ids']　:  tensor([[50257,  2504,   318,   257,  1049,  2126,    13]])\n",
            "inputs['input_ids'].shape　:  torch.Size([1, 7])\n",
            "inputs['input_ids'] token :  ['<sos>', 'That', 'Ġis', 'Ġa', 'Ġgreat', 'Ġidea', '.']\n",
            "outputs['input_ids']　:  tensor([[ 1901, 13559,  9994,   328,     7]])\n",
            "outputs['input_ids'].shape　:  torch.Size([1, 5])\n",
            "outputs['input_ids'] token :  ['それは', '素晴らしい', 'アイデア', 'だ', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_jp = tokenizer_jp.vocab_size+3\n",
        "vocab_size_en = tokenizer.vocab_size+3\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "max_seq_len = 256\n",
        "hidden_dim = 256\n",
        "\n",
        "model = Transformer(vocab_size_en = vocab_size_en,\n",
        "                    vocab_size_jp = vocab_size_jp,\n",
        "                    d_model = d_model,\n",
        "                    num_heads = num_heads,\n",
        "                    max_seq_len = max_seq_len,\n",
        "                    hidden_dim = hidden_dim)\n",
        "\n",
        "output = model(src = inputs['input_ids'],\n",
        "                 tgt = outputs['input_ids'],\n",
        "                 src_mask = inputs['attention_mask'],\n",
        "                 tgt_mask = outputs['attention_mask'])\n",
        "\n",
        "print(\"output.shape : \", output.shape)\n",
        "\n",
        "outputs_IDs = torch.argmax(output, dim=-1)\n",
        "print(\"outputs_IDs : \", outputs_IDs)\n",
        "\n",
        "# モデルが出力した数値(id)を各単語に逆変換\n",
        "generated_text = tokenizer.decode(outputs_IDs[0])\n",
        "print(\"generated_text : \", generated_text)\n",
        "print(\"model_output token : \", tokenizer.convert_ids_to_tokens(outputs_IDs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDoH6L8ZsreK",
        "outputId": "5576a612-8d2b-4f2f-f678-78ec4dd66c39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output.shape :  torch.Size([1, 5, 32003])\n",
            "outputs_IDs :  tensor([[25180, 18853, 18457,  8298, 19390]])\n",
            "generated_text :  acketsimity capac001 Request\n",
            "model_output token :  ['ackets', 'imity', 'Ġcapac', '001', 'ĠRequest']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "現状は何も学習していない乱数によるパラメータなので，期待している次単語予測による文章が生成できていないが，<br>\n",
        "Transformerの大まかなデータの流れはこのようになっている．<br>\n",
        "<br>\n",
        "このプログラムを参考に，色々データの中身や形状をPrint()して表示させてみて，理解につなげてみよう！<br>\n",
        "<br>\n",
        "以上<br>\n",
        "<br>\n",
        "中部大学 機械知覚&ロボティクスグループ（藤吉研究室）<br>\n",
        "増田 大河\n"
      ],
      "metadata": {
        "id": "u37SRcmNa4ZO"
      }
    }
  ]
}